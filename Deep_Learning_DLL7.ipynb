{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning DLL7",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "34ryuXsFjQow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4b1f44-c9b1-4c5b-e9e9-3bf7033b0486"
      },
      "source": [
        "# импортируем модули\n",
        "import torch\n",
        "import torch.nn.functional as func\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# чмитаем файл без заголовков и делим по пробелам\n",
        "dataset = pd.read_csv(\"housing.csv\", delim_whitespace = True, header=None)\n",
        "\n",
        "# называем столбцы\n",
        "dataset.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B-1000', 'LSTAT', 'MEDV']\n",
        "\n",
        "# делаем тензоры\n",
        "x_ar = torch.from_numpy(dataset.to_numpy())[:,:-1].float()\n",
        "y_ar = torch.from_numpy(dataset.to_numpy()) [:,-1]\n",
        "\n",
        "# создаём таблицу с нормализованными данными\n",
        "means = x_ar.mean(dim=0, keepdim=True)\n",
        "stds = x_ar.std(dim=0, keepdim=True)\n",
        "normalized_data = (x_ar - means) / stds\n",
        "\n",
        "# в таблице с нормализованными данными заменяем dummy variables на ненормализованные\n",
        "for i in range(506):\n",
        "  normalized_data[i, 3] = torch.tensor([x_ar[i, 3]])\n",
        "  normalized_data[i, 8] = torch.tensor([x_ar[i, 8]])\n",
        "\n",
        "normalized_data.shape\n",
        "y_ar = y_ar.reshape(506, 1)\n",
        "\n",
        "# задаём датасет\n",
        "training_data = TensorDataset(normalized_data, y_ar)\n",
        "\n",
        "# задаём linear  model, у нас 13 переменных входит, 1 на выходе\n",
        "model = nn.Linear(13, 1)\n",
        "\n",
        "# создаём оптимизатор \n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.00001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# создаём несколько batches к нашей модели\n",
        "batch_size = 10\n",
        "train_dl = DataLoader(training_data, batch_size, shuffle=True)\n",
        "\n",
        "# функция для обучения модели\n",
        "def fit(train_dl, num_epochs, model, loss_fn, opt):\n",
        "    \n",
        "    # повторяем заданное количество раз (3000)\n",
        "    for epoch in range(num_epochs+1):\n",
        "        \n",
        "        # обучаем модель для каждого batch\n",
        "        for xb,yb in train_dl:\n",
        "            \n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred.view(-1), yb.float())\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "          print(f'{epoch} : {loss_fn(model(normalized_data).view(-1), y_ar)}')\n",
        "\n",
        "# запускаем обучение\n",
        "fit(train_dl, 3000, model, loss_fn , opt)\n",
        "\n",
        "# получаем предсказанное значение y\n",
        "preds = model(normalized_data)\n",
        "preds\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([6, 1])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([506, 1])) that is different to the input size (torch.Size([506])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 : 484.8786055249292\n",
            "100 : 237.6382026835461\n",
            "200 : 200.0223596198455\n",
            "300 : 179.49166641927272\n",
            "400 : 166.5415058757388\n",
            "500 : 157.28894383207634\n",
            "600 : 150.15948095995012\n",
            "700 : 144.29597521083784\n",
            "800 : 139.38617706384468\n",
            "900 : 135.16554000281437\n",
            "1000 : 131.53179540639434\n",
            "1100 : 128.3466602316709\n",
            "1200 : 125.53244684531691\n",
            "1300 : 123.0456965527081\n",
            "1400 : 120.82579563852646\n",
            "1500 : 118.88292744940941\n",
            "1600 : 117.10962166139872\n",
            "1700 : 115.5133252518934\n",
            "1800 : 114.08086107421609\n",
            "1900 : 112.77136011206689\n",
            "2000 : 111.58353724587796\n",
            "2100 : 110.50471729804295\n",
            "2200 : 109.45059070730585\n",
            "2300 : 108.52728052761724\n",
            "2400 : 107.64970078242462\n",
            "2500 : 106.81706521994876\n",
            "2600 : 106.05232980937735\n",
            "2700 : 105.37129384487012\n",
            "2800 : 104.71129874875739\n",
            "2900 : 104.06600622430605\n",
            "3000 : 103.48395755360731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19.1465],\n",
              "        [21.4526],\n",
              "        [20.6977],\n",
              "        [22.0427],\n",
              "        [21.9155],\n",
              "        [22.6210],\n",
              "        [23.7730],\n",
              "        [23.6733],\n",
              "        [23.7811],\n",
              "        [23.6949],\n",
              "        [23.3581],\n",
              "        [23.8849],\n",
              "        [23.4923],\n",
              "        [18.1093],\n",
              "        [17.9923],\n",
              "        [18.1579],\n",
              "        [17.6923],\n",
              "        [17.9506],\n",
              "        [17.3653],\n",
              "        [18.2500],\n",
              "        [18.1141],\n",
              "        [18.1049],\n",
              "        [17.7494],\n",
              "        [18.1388],\n",
              "        [18.1411],\n",
              "        [17.6224],\n",
              "        [18.1308],\n",
              "        [17.2015],\n",
              "        [17.6597],\n",
              "        [17.3388],\n",
              "        [17.7834],\n",
              "        [17.8729],\n",
              "        [16.2298],\n",
              "        [17.9311],\n",
              "        [16.5326],\n",
              "        [22.4297],\n",
              "        [22.2383],\n",
              "        [22.2676],\n",
              "        [21.9630],\n",
              "        [20.7600],\n",
              "        [20.3731],\n",
              "        [22.0695],\n",
              "        [22.6175],\n",
              "        [22.6093],\n",
              "        [22.9572],\n",
              "        [23.3063],\n",
              "        [23.0778],\n",
              "        [23.1294],\n",
              "        [23.4608],\n",
              "        [23.4169],\n",
              "        [24.5169],\n",
              "        [24.6585],\n",
              "        [24.0477],\n",
              "        [24.4346],\n",
              "        [10.9903],\n",
              "        [23.7584],\n",
              "        [18.3493],\n",
              "        [25.2649],\n",
              "        [24.8346],\n",
              "        [25.2197],\n",
              "        [25.4144],\n",
              "        [25.2880],\n",
              "        [24.9821],\n",
              "        [24.3471],\n",
              "        [22.3672],\n",
              "        [20.9575],\n",
              "        [21.3777],\n",
              "        [19.4262],\n",
              "        [19.6663],\n",
              "        [19.4934],\n",
              "        [20.1588],\n",
              "        [20.5182],\n",
              "        [20.5926],\n",
              "        [20.2122],\n",
              "        [18.1775],\n",
              "        [18.3571],\n",
              "        [18.4794],\n",
              "        [18.5032],\n",
              "        [18.4032],\n",
              "        [18.7640],\n",
              "        [20.8695],\n",
              "        [21.2424],\n",
              "        [21.2126],\n",
              "        [21.4002],\n",
              "        [21.7968],\n",
              "        [21.7137],\n",
              "        [22.0226],\n",
              "        [22.1765],\n",
              "        [19.8237],\n",
              "        [19.5293],\n",
              "        [20.0614],\n",
              "        [20.1766],\n",
              "        [21.9055],\n",
              "        [21.9671],\n",
              "        [22.2470],\n",
              "        [19.6556],\n",
              "        [20.3205],\n",
              "        [18.8528],\n",
              "        [18.7267],\n",
              "        [19.2915],\n",
              "        [16.1897],\n",
              "        [16.1265],\n",
              "        [13.9407],\n",
              "        [16.6712],\n",
              "        [16.7143],\n",
              "        [16.9657],\n",
              "        [16.8673],\n",
              "        [16.6240],\n",
              "        [16.5169],\n",
              "        [16.5210],\n",
              "        [16.3412],\n",
              "        [17.7673],\n",
              "        [18.4348],\n",
              "        [18.2477],\n",
              "        [18.1621],\n",
              "        [17.9825],\n",
              "        [18.1025],\n",
              "        [18.3995],\n",
              "        [17.8676],\n",
              "        [18.3849],\n",
              "        [21.5356],\n",
              "        [21.4575],\n",
              "        [21.4671],\n",
              "        [21.3001],\n",
              "        [21.5927],\n",
              "        [21.5364],\n",
              "        [21.3161],\n",
              "        [12.5158],\n",
              "        [11.9260],\n",
              "        [12.3950],\n",
              "        [11.9611],\n",
              "        [11.8781],\n",
              "        [11.9360],\n",
              "        [12.3921],\n",
              "        [11.2601],\n",
              "        [11.8768],\n",
              "        [12.1381],\n",
              "        [11.8955],\n",
              "        [12.2597],\n",
              "        [12.0335],\n",
              "        [11.7920],\n",
              "        [12.3511],\n",
              "        [17.4604],\n",
              "        [16.5114],\n",
              "        [17.2677],\n",
              "        [14.5235],\n",
              "        [15.3651],\n",
              "        [17.2795],\n",
              "        [16.7904],\n",
              "        [16.4858],\n",
              "        [16.6791],\n",
              "        [17.1988],\n",
              "        [18.2983],\n",
              "        [16.0287],\n",
              "        [16.9808],\n",
              "        [14.4689],\n",
              "        [14.9450],\n",
              "        [19.1967],\n",
              "        [19.8839],\n",
              "        [16.5363],\n",
              "        [20.2714],\n",
              "        [18.7353],\n",
              "        [19.2290],\n",
              "        [18.6760],\n",
              "        [19.9219],\n",
              "        [18.3716],\n",
              "        [18.1308],\n",
              "        [18.5637],\n",
              "        [18.7669],\n",
              "        [18.8904],\n",
              "        [19.2962],\n",
              "        [19.5501],\n",
              "        [24.1366],\n",
              "        [23.4794],\n",
              "        [23.8224],\n",
              "        [22.9563],\n",
              "        [23.4369],\n",
              "        [23.5512],\n",
              "        [23.0045],\n",
              "        [23.7121],\n",
              "        [23.1192],\n",
              "        [24.3980],\n",
              "        [23.8418],\n",
              "        [24.4170],\n",
              "        [24.9587],\n",
              "        [24.2419],\n",
              "        [22.8446],\n",
              "        [20.2741],\n",
              "        [20.3195],\n",
              "        [19.9163],\n",
              "        [19.7760],\n",
              "        [20.1737],\n",
              "        [19.7786],\n",
              "        [20.2619],\n",
              "        [20.4192],\n",
              "        [23.8835],\n",
              "        [20.9213],\n",
              "        [20.6364],\n",
              "        [20.8574],\n",
              "        [15.6601],\n",
              "        [15.4050],\n",
              "        [19.3425],\n",
              "        [17.9245],\n",
              "        [24.7055],\n",
              "        [24.5389],\n",
              "        [21.5007],\n",
              "        [21.3188],\n",
              "        [21.7470],\n",
              "        [22.1328],\n",
              "        [22.9825],\n",
              "        [22.5498],\n",
              "        [22.8011],\n",
              "        [22.3537],\n",
              "        [21.0978],\n",
              "        [20.8491],\n",
              "        [21.4165],\n",
              "        [24.7604],\n",
              "        [23.7259],\n",
              "        [24.9374],\n",
              "        [24.7196],\n",
              "        [26.0462],\n",
              "        [26.4556],\n",
              "        [25.9174],\n",
              "        [25.6154],\n",
              "        [24.1818],\n",
              "        [23.7024],\n",
              "        [24.4933],\n",
              "        [25.0260],\n",
              "        [24.0950],\n",
              "        [25.1895],\n",
              "        [25.8651],\n",
              "        [24.8053],\n",
              "        [24.0012],\n",
              "        [24.0253],\n",
              "        [25.8117],\n",
              "        [25.7363],\n",
              "        [26.1368],\n",
              "        [24.8730],\n",
              "        [24.2134],\n",
              "        [24.3166],\n",
              "        [24.0811],\n",
              "        [24.9296],\n",
              "        [24.4156],\n",
              "        [24.1604],\n",
              "        [23.3215],\n",
              "        [23.2016],\n",
              "        [22.6586],\n",
              "        [22.8543],\n",
              "        [22.4040],\n",
              "        [22.0784],\n",
              "        [22.3186],\n",
              "        [22.2284],\n",
              "        [21.7857],\n",
              "        [20.5922],\n",
              "        [18.2756],\n",
              "        [18.3115],\n",
              "        [22.4518],\n",
              "        [23.6835],\n",
              "        [24.9411],\n",
              "        [25.4952],\n",
              "        [24.9382],\n",
              "        [24.7497],\n",
              "        [23.9755],\n",
              "        [24.8218],\n",
              "        [25.0365],\n",
              "        [26.2194],\n",
              "        [24.8486],\n",
              "        [24.5606],\n",
              "        [25.3768],\n",
              "        [23.3276],\n",
              "        [22.4382],\n",
              "        [22.1372],\n",
              "        [22.2273],\n",
              "        [21.7463],\n",
              "        [23.3661],\n",
              "        [22.6686],\n",
              "        [22.8678],\n",
              "        [23.1830],\n",
              "        [22.7952],\n",
              "        [27.6050],\n",
              "        [26.9457],\n",
              "        [27.4880],\n",
              "        [27.5950],\n",
              "        [23.9165],\n",
              "        [19.1057],\n",
              "        [19.7829],\n",
              "        [18.9910],\n",
              "        [24.9193],\n",
              "        [24.9365],\n",
              "        [24.2353],\n",
              "        [21.4422],\n",
              "        [21.1531],\n",
              "        [21.5742],\n",
              "        [23.5245],\n",
              "        [23.8005],\n",
              "        [23.1726],\n",
              "        [23.4307],\n",
              "        [23.9446],\n",
              "        [22.1658],\n",
              "        [21.4554],\n",
              "        [22.0749],\n",
              "        [24.7376],\n",
              "        [24.5384],\n",
              "        [24.2452],\n",
              "        [26.0043],\n",
              "        [26.6973],\n",
              "        [26.1783],\n",
              "        [26.6700],\n",
              "        [20.0074],\n",
              "        [20.4441],\n",
              "        [20.0135],\n",
              "        [20.1119],\n",
              "        [20.4995],\n",
              "        [20.2826],\n",
              "        [19.9825],\n",
              "        [20.6579],\n",
              "        [20.2385],\n",
              "        [20.3959],\n",
              "        [19.9259],\n",
              "        [20.0027],\n",
              "        [21.2805],\n",
              "        [21.3526],\n",
              "        [21.5519],\n",
              "        [21.9369],\n",
              "        [21.1620],\n",
              "        [20.9364],\n",
              "        [21.1435],\n",
              "        [21.3055],\n",
              "        [17.3178],\n",
              "        [16.8266],\n",
              "        [17.0233],\n",
              "        [18.5947],\n",
              "        [18.1396],\n",
              "        [22.8719],\n",
              "        [22.8491],\n",
              "        [23.1006],\n",
              "        [23.3349],\n",
              "        [23.3840],\n",
              "        [23.1195],\n",
              "        [23.2263],\n",
              "        [23.3761],\n",
              "        [19.4027],\n",
              "        [14.0703],\n",
              "        [18.9334],\n",
              "        [18.4914],\n",
              "        [17.7963],\n",
              "        [17.7009],\n",
              "        [18.3037],\n",
              "        [21.6318],\n",
              "        [14.1845],\n",
              "        [14.7414],\n",
              "        [16.0051],\n",
              "        [16.5949],\n",
              "        [26.3343],\n",
              "        [16.4141],\n",
              "        [16.1436],\n",
              "        [24.0482],\n",
              "        [25.3499],\n",
              "        [25.2690],\n",
              "        [24.7335],\n",
              "        [24.4802],\n",
              "        [24.4457],\n",
              "        [25.7328],\n",
              "        [25.4653],\n",
              "        [23.6890],\n",
              "        [27.6044],\n",
              "        [26.0196],\n",
              "        [24.1836],\n",
              "        [27.5693],\n",
              "        [26.4226],\n",
              "        [26.0562],\n",
              "        [25.0387],\n",
              "        [25.6732],\n",
              "        [24.8378],\n",
              "        [23.5846],\n",
              "        [21.0292],\n",
              "        [22.1344],\n",
              "        [23.7637],\n",
              "        [20.5436],\n",
              "        [22.2271],\n",
              "        [ 3.5790],\n",
              "        [22.4651],\n",
              "        [24.7129],\n",
              "        [25.0025],\n",
              "        [21.8745],\n",
              "        [22.7846],\n",
              "        [21.5417],\n",
              "        [21.4575],\n",
              "        [23.6158],\n",
              "        [25.1832],\n",
              "        [25.2555],\n",
              "        [25.0435],\n",
              "        [24.4773],\n",
              "        [24.4993],\n",
              "        [23.5731],\n",
              "        [24.1807],\n",
              "        [24.9086],\n",
              "        [25.0499],\n",
              "        [17.2556],\n",
              "        [23.4469],\n",
              "        [20.2463],\n",
              "        [22.8554],\n",
              "        [23.8106],\n",
              "        [21.0828],\n",
              "        [15.8071],\n",
              "        [ 9.6824],\n",
              "        [23.3647],\n",
              "        [24.2554],\n",
              "        [25.4874],\n",
              "        [21.7065],\n",
              "        [12.3349],\n",
              "        [20.8071],\n",
              "        [21.0437],\n",
              "        [19.9257],\n",
              "        [13.6269],\n",
              "        [18.7668],\n",
              "        [20.2515],\n",
              "        [18.5985],\n",
              "        [ 5.3238],\n",
              "        [19.7035],\n",
              "        [22.8540],\n",
              "        [24.2094],\n",
              "        [24.1808],\n",
              "        [22.4409],\n",
              "        [22.9006],\n",
              "        [19.7811],\n",
              "        [21.8804],\n",
              "        [14.2032],\n",
              "        [22.2850],\n",
              "        [21.4086],\n",
              "        [22.9991],\n",
              "        [22.1411],\n",
              "        [23.6253],\n",
              "        [22.4032],\n",
              "        [20.6076],\n",
              "        [20.4312],\n",
              "        [19.2675],\n",
              "        [19.0267],\n",
              "        [19.7348],\n",
              "        [24.0895],\n",
              "        [20.6642],\n",
              "        [23.3164],\n",
              "        [24.7161],\n",
              "        [23.2362],\n",
              "        [21.7769],\n",
              "        [20.1733],\n",
              "        [23.7611],\n",
              "        [23.5170],\n",
              "        [24.0619],\n",
              "        [23.5354],\n",
              "        [21.0422],\n",
              "        [24.2858],\n",
              "        [24.8991],\n",
              "        [23.0819],\n",
              "        [20.3722],\n",
              "        [22.0673],\n",
              "        [22.2668],\n",
              "        [21.3415],\n",
              "        [23.2782],\n",
              "        [24.7614],\n",
              "        [23.5736],\n",
              "        [25.2733],\n",
              "        [24.5858],\n",
              "        [24.7662],\n",
              "        [24.8866],\n",
              "        [25.8127],\n",
              "        [23.2723],\n",
              "        [26.2527],\n",
              "        [23.7045],\n",
              "        [24.7340],\n",
              "        [26.7222],\n",
              "        [27.4314],\n",
              "        [26.6195],\n",
              "        [25.3369],\n",
              "        [26.1481],\n",
              "        [25.3297],\n",
              "        [25.9441],\n",
              "        [23.9544],\n",
              "        [24.7871],\n",
              "        [23.8120],\n",
              "        [26.7941],\n",
              "        [26.5075],\n",
              "        [26.2674],\n",
              "        [27.7396],\n",
              "        [26.9417],\n",
              "        [26.5110],\n",
              "        [26.3517],\n",
              "        [26.6035],\n",
              "        [ 3.4038],\n",
              "        [ 2.9026],\n",
              "        [ 2.8143],\n",
              "        [ 2.9352],\n",
              "        [ 2.9847],\n",
              "        [18.3973],\n",
              "        [18.0103],\n",
              "        [17.9833],\n",
              "        [18.5454],\n",
              "        [18.3663],\n",
              "        [18.1640],\n",
              "        [18.6012],\n",
              "        [18.2476],\n",
              "        [15.1351],\n",
              "        [15.7156],\n",
              "        [15.1521],\n",
              "        [15.2351],\n",
              "        [15.8685]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YG5-hm6WGRs",
        "outputId": "04e2eb32-b7a7-4f55-f22f-644381563991"
      },
      "source": [
        ">>> x = torch.randn(4, 4)\n",
        ">>> x.size()\n",
        "torch.Size([4, 4])\n",
        "x.view(16)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.9363,  0.9018, -0.5338, -1.3554, -2.6663,  1.5833, -1.2083, -1.2063,\n",
              "        -0.5137, -0.1437,  0.0956,  0.2765, -0.7071, -0.4512, -1.1933, -0.1976])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}